package com.hadoop.hdfs.hdfs_api;

import com.hadoop.hdfs.common.GetFileSystemClass;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

import java.io.BufferedReader;
import java.io.InputStream;
import java.io.InputStreamReader;

/**
 * @Auther 陈郑游
 * @Data 2017/8/30 0030
 * @Description:
 * @CSDN:http://blog.csdn.net/javawebrookie
 * @GITHUB:https://github.com/AndyCZY
 */
public class HdfsOpenTest {

    public static void main(String[] args) throws Exception{
        openRead();    //读取文件
    }

    //读取文件
    private static void openRead() throws Exception{
        // get filesystem
        FileSystem fileSystem = GetFileSystemClass.getFileSystem();
        InputStream is = fileSystem.open(new Path("/chenzy/mapreduce/wordcount/input/test.txt"));
        BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(is));

        String line = null;
        while ((line = bufferedReader.readLine()) != null){
            System.out.println(line);
        }

        is.close();
        bufferedReader.close();
        fileSystem.close();
    }
}
